# typed: false
# frozen_string_literal: true

# This file was generated by Homebrew. Please do not edit it directly.
class DeltaCli < Formula
  desc "Offline AI Assistant powered by llama.cpp"
  homepage "https://github.com/nile-agi/delta"
  url "https://github.com/nile-agi/delta/archive/refs/tags/v1.0.0.tar.gz"
  sha256 "PLACEHOLDER_SHA256"
  license "MIT"
  head "https://github.com/nile-agi/delta.git", branch: "main", submodules: true

  depends_on "cmake" => :build
  depends_on "curl" => :build
  depends_on "pkg-config" => :build

  on_macos do
    depends_on :macos
  end

  on_linux do
    depends_on "gcc" => :build
  end

  def install
    # Ensure submodules are initialized and updated
    system "git", "submodule", "update", "--init", "--recursive"
    
    # Create build directory
    mkdir "build" do
      system "cmake", "..",
                    "-DCMAKE_BUILD_TYPE=Release",
                    "-DGGML_METAL=#{OS.mac? ? "ON" : "OFF"}",
                    "-DLLAMA_CUDA=OFF",
                    "-DLLAMA_VULKAN=OFF",
                    "-DLLAMA_HIPBLAS=OFF",
                    "-DBUILD_SERVER=ON",
                    "-DUSE_CURL=ON",
                    *std_cmake_args
      system "make", "-j#{ENV.make_jobs}"
    end

    # Install binaries
    bin.install "build/delta"
    bin.install "build/delta-server"

    # Install web UI
    if Dir.exist?("vendor/llama.cpp/tools/server/public")
      share.install "vendor/llama.cpp/tools/server/public" => "delta-cli/webui"
    end
  end

  test do
    system "#{bin}/delta", "--version"
  end
end

